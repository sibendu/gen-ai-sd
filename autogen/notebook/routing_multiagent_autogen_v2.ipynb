{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b43a2a-69b0-46ca-bb51-857fc4d55d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure/gpt-4\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "model=os.environ.get('model')\n",
    "print(model)\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.environ.get('AZURE_API_KEY')\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.environ.get('AZURE_API_KEY')\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = os.environ.get('AZURE_API_VERSION')\n",
    "os.environ[\"AUTOGEN_USE_DOCKER\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "605656e5-2b7f-4b7f-8c55-5ce50f9282b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from typing import Dict, List, Tuple, Optional, Literal, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd4f8add-8c0d-4a2b-aaa2-2a6516e38321",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AzureOpenAIAgent' from 'autogen' (C:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautogen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIAgent\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AzureOpenAIAgent' from 'autogen' (C:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autogen import AzureOpenAIAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cbc9bae-90a6-46a0-8073-557fe03cee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Azure OpenAI\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4\",  # Or your specific Azure OpenAI deployment name\n",
    "        \"api_type\": \"azure\",\n",
    "        \"api_key\": os.environ.get('AZURE_API_KEY'),\n",
    "        \"api_base\": os.environ.get('AZURE_API_KEY'),  # Your Azure OpenAI endpoint\n",
    "        \"api_version\": os.environ.get('AZURE_API_VERSION')  # Update with your API version\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a9edec-7eb1-4e4e-ba27-0200a6a7504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure termination message for conversations\n",
    "termination_msg = lambda x: isinstance(x, str) and \"TERMINATE\" in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4c4c23a-c7ba-41c7-9775-f6de7ef57d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user proxy\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"last_n_messages\": 3, \"work_dir\": \"workspace\"},\n",
    "    system_message=\"I am a user proxy that represents the customer.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d451fc60-f75a-44ef-83e9-55024494f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents for travel domain\n",
    "flight_agent = autogen.AssistantAgent(\n",
    "    name=\"flight_agent\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"\"\"You are a flight booking specialist. You help customers with flight booking related queries.\n",
    "    End your response with TERMINATE when the task is complete.\"\"\"\n",
    ")\n",
    "\n",
    "train_agent = autogen.AssistantAgent(\n",
    "    name=\"train_agent\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"\"\"You are a train booking specialist. You help customers with train booking related queries.\n",
    "    End your response with TERMINATE when the task is complete.\"\"\"\n",
    ")\n",
    "\n",
    "travel_assistant_agent = autogen.AssistantAgent(\n",
    "    name=\"travel_assistant_agent\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"\"\"You are a general travel assistant. You help customers with general travel related queries \n",
    "    that are not specifically about flights or trains.\n",
    "    End your response with TERMINATE when the task is complete.\"\"\"\n",
    ")\n",
    "\n",
    "# Create agents for finance domain\n",
    "stock_agent = autogen.AssistantAgent(\n",
    "    name=\"stock_agent\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"\"\"You are a stock market specialist. You help customers with stock market related queries.\n",
    "    End your response with TERMINATE when the task is complete.\"\"\"\n",
    ")\n",
    "\n",
    "mutual_fund_agent = autogen.AssistantAgent(\n",
    "    name=\"mutual_fund_agent\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"\"\"You are a mutual fund specialist. You help customers with mutual fund related queries.\n",
    "    End your response with TERMINATE when the task is complete.\"\"\"\n",
    ")\n",
    "\n",
    "finance_assistant_agent = autogen.AssistantAgent(\n",
    "    name=\"finance_assistant_agent\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"\"\"You are a general finance assistant. You help customers with general finance related queries \n",
    "    that are not specifically about stocks or mutual funds.\n",
    "    End your response with TERMINATE when the task is complete.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19e42fa9-d5f5-466c-aab0-c20d3beae6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create travel supervisor agent\n",
    "class TravelSupervisorAgent(autogen.AssistantAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"travel_supervisor\",\n",
    "            llm_config={\"config_list\": config_list},\n",
    "            system_message=\"\"\"You are a travel domain supervisor. \n",
    "            Your job is to analyze customer queries and route them to the appropriate travel agent:\n",
    "            - flight_agent: For flight booking, flight status, or any flight related queries\n",
    "            - train_agent: For train booking, train status, or any train related queries\n",
    "            - travel_assistant_agent: For all other travel related queries\n",
    "            \n",
    "            Determine the most appropriate agent and explain your routing decision.\"\"\"\n",
    "        )\n",
    "        self.register_reply(\n",
    "            [flight_agent, train_agent, travel_assistant_agent, user_proxy],\n",
    "            TravelSupervisorAgent.route_query\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def route_query(self, messages: List[Dict], sender, config):\n",
    "        query = messages[-1][\"content\"]\n",
    "        # Simple keyword-based routing logic\n",
    "        if any(keyword in query.lower() for keyword in [\"flight\", \"airplane\", \"airport\", \"airline\"]):\n",
    "            target_agent = flight_agent\n",
    "            routing_explanation = \"Routing to flight_agent as the query appears to be flight-related.\"\n",
    "        elif any(keyword in query.lower() for keyword in [\"train\", \"railway\", \"station\", \"rail\"]):\n",
    "            target_agent = train_agent\n",
    "            routing_explanation = \"Routing to train_agent as the query appears to be train-related.\"\n",
    "        else:\n",
    "            target_agent = travel_assistant_agent\n",
    "            routing_explanation = \"Routing to travel_assistant_agent as the query is travel-related but not specifically about flights or trains.\"\n",
    "        \n",
    "        response = f\"{routing_explanation}\\n\\n@{target_agent.name} Please address the following travel query: {query}\"\n",
    "        return {\"content\": response}\n",
    "\n",
    "# Create finance supervisor agent\n",
    "class FinanceSupervisorAgent(autogen.AssistantAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"finance_supervisor\",\n",
    "            llm_config={\"config_list\": config_list},\n",
    "            system_message=\"\"\"You are a finance domain supervisor. \n",
    "            Your job is to analyze customer queries and route them to the appropriate finance agent:\n",
    "            - stock_agent: For stock market, trading, shares, or any stock related queries\n",
    "            - mutual_fund_agent: For mutual funds, index funds, ETFs, or any fund related queries\n",
    "            - finance_assistant_agent: For all other finance related queries\n",
    "            \n",
    "            Determine the most appropriate agent and explain your routing decision.\"\"\"\n",
    "        )\n",
    "        self.register_reply(\n",
    "            [stock_agent, mutual_fund_agent, finance_assistant_agent, user_proxy],\n",
    "            FinanceSupervisorAgent.route_query\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def route_query(self, messages: List[Dict], sender, config):\n",
    "        query = messages[-1][\"content\"]\n",
    "        # Simple keyword-based routing logic\n",
    "        if any(keyword in query.lower() for keyword in [\"stock\", \"share\", \"trading\", \"market\", \"investor\", \"equity\"]):\n",
    "            target_agent = stock_agent\n",
    "            routing_explanation = \"Routing to stock_agent as the query appears to be stock market-related.\"\n",
    "        elif any(keyword in query.lower() for keyword in [\"mutual fund\", \"etf\", \"index fund\", \"fund\", \"nav\", \"sip\"]):\n",
    "            target_agent = mutual_fund_agent\n",
    "            routing_explanation = \"Routing to mutual_fund_agent as the query appears to be fund-related.\"\n",
    "        else:\n",
    "            target_agent = finance_assistant_agent\n",
    "            routing_explanation = \"Routing to finance_assistant_agent as the query is finance-related but not specifically about stocks or mutual funds.\"\n",
    "        \n",
    "        response = f\"{routing_explanation}\\n\\n@{target_agent.name} Please address the following finance query: {query}\"\n",
    "        return {\"content\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9041158-1647-4e17-97c7-58f5ff379b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main supervisor agent\n",
    "class MainSupervisorAgent(autogen.AssistantAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"main_supervisor\",\n",
    "            llm_config={\"config_list\": config_list},\n",
    "            system_message=\"\"\"You are the main supervisor agent. \n",
    "            Your job is to analyze customer queries and route them to the appropriate domain supervisor:\n",
    "            - travel_supervisor: For travel related queries including flights, trains, hotels, vacations, etc.\n",
    "            - finance_supervisor: For finance related queries including stocks, mutual funds, investments, etc.\n",
    "            \n",
    "            Determine the most appropriate supervisor and explain your routing decision.\"\"\"\n",
    "        )\n",
    "        self.register_reply(\n",
    "            [travel_supervisor, finance_supervisor, user_proxy],\n",
    "            MainSupervisorAgent.route_query\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def route_query(self, messages: List[Dict], sender, config):\n",
    "        query = messages[-1][\"content\"]\n",
    "        # Simple keyword-based routing logic\n",
    "        travel_keywords = [\"travel\", \"flight\", \"train\", \"hotel\", \"vacation\", \"booking\", \"trip\", \"journey\", \"tourist\", \"airport\", \"station\"]\n",
    "        finance_keywords = [\"finance\", \"money\", \"investment\", \"stock\", \"fund\", \"mutual\", \"share\", \"trading\", \"market\", \"portfolio\", \"dividend\", \"financial\"]\n",
    "        \n",
    "        travel_score = sum(1 for keyword in travel_keywords if keyword in query.lower())\n",
    "        finance_score = sum(1 for keyword in finance_keywords if keyword in query.lower())\n",
    "        \n",
    "        if travel_score > finance_score:\n",
    "            target_supervisor = travel_supervisor\n",
    "            routing_explanation = \"Routing to travel_supervisor as the query appears to be travel-related.\"\n",
    "        else:\n",
    "            target_supervisor = finance_supervisor\n",
    "            routing_explanation = \"Routing to finance_supervisor as the query appears to be finance-related.\"\n",
    "        \n",
    "        response = f\"{routing_explanation}\\n\\n@{target_supervisor.name} Please determine the appropriate agent for the following query: {query}\"\n",
    "        return {\"content\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5abd4c6-2697-4210-bc6b-bd0d0820b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize supervisor agents\n",
    "travel_supervisor = TravelSupervisorAgent()\n",
    "finance_supervisor = FinanceSupervisorAgent()\n",
    "main_supervisor = MainSupervisorAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1347e342-8736-4d89-bafd-ba6082a5ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent groupchat for each domain\n",
    "travel_groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, travel_supervisor, flight_agent, train_agent, travel_assistant_agent],\n",
    "    messages=[],\n",
    "    max_round=10\n",
    ")\n",
    "\n",
    "finance_groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, finance_supervisor, stock_agent, mutual_fund_agent, finance_assistant_agent],\n",
    "    messages=[],\n",
    "    max_round=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17cf556d-1f19-4bdf-9956-b59706595940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main groupchat\n",
    "main_groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, main_supervisor, travel_supervisor, finance_supervisor],\n",
    "    messages=[],\n",
    "    max_round=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11b162a9-6765-4a73-b3ff-4a2a9d085fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize managers for each groupchat\n",
    "travel_manager = autogen.GroupChatManager(groupchat=travel_groupchat, llm_config={\"config_list\": config_list}, is_termination_msg=termination_msg)\n",
    "finance_manager = autogen.GroupChatManager(groupchat=finance_groupchat, llm_config={\"config_list\": config_list}, is_termination_msg=termination_msg)\n",
    "main_manager = autogen.GroupChatManager(groupchat=main_groupchat, llm_config={\"config_list\": config_list}, is_termination_msg=termination_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45b3a9be-205e-4018-a62a-946e1c38ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_customer_query(query: str):\n",
    "    \"\"\"Process a customer query through the hierarchical multi-agent system\"\"\"\n",
    "    \n",
    "    print(f\"Customer Query: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Start the conversation with the main supervisor\n",
    "    user_proxy.initiate_chat(main_manager, message=query)\n",
    "\n",
    "    # The conversation flow:\n",
    "    # 1. main_supervisor determines if query is travel or finance related\n",
    "    # 2. routes to appropriate domain supervisor\n",
    "    # 3. domain supervisor routes to specific agent\n",
    "    # 4. specific agent addresses the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5cebab1-3840-47ad-bc9a-a7feeaff34c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Query: I need to book a flight from New York to London next week\n",
      "--------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "I need to book a flight from New York to London next week\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'api_base'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Example travel query\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mprocess_customer_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI need to book a flight from New York to London next week\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Example finance query\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     process_customer_query(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the best mutual funds to invest in for long-term growth?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 8\u001b[0m, in \u001b[0;36mprocess_customer_query\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Start the conversation with the main supervisor\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1499\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[0;32m   1497\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1498\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1499\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1500\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[0;32m   1501\u001b[0m     summary_method,\n\u001b[0;32m   1502\u001b[0m     summary_args,\n\u001b[0;32m   1503\u001b[0m     recipient,\n\u001b[0;32m   1504\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m   1505\u001b[0m )\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1191\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m   1189\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m-> 1191\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1299\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1299\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2437\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[0;32m   2435\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   2436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[1;32m-> 2437\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[0;32m   2439\u001b[0m         log_event(\n\u001b[0;32m   2440\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2441\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2445\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[0;32m   2446\u001b[0m         )\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\groupchat.py:1183\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m   1180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;66;03m# select the next speaker\u001b[39;00m\n\u001b[1;32m-> 1183\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m \u001b[43mgroupchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[0;32m   1185\u001b[0m         iostream \u001b[38;5;241m=\u001b[39m IOStream\u001b[38;5;241m.\u001b[39mget_default()\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\groupchat.py:578\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[1;34m(self, last_speaker, selector)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_agent(last_speaker)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;66;03m# auto speaker selection with 2-agent chat\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_select_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_speaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\groupchat.py:761\u001b[0m, in \u001b[0;36mGroupChat._auto_select_speaker\u001b[1;34m(self, last_speaker, selector, messages, agents)\u001b[0m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_speaker_selection_transforms\u001b[38;5;241m.\u001b[39madd_to_agent(speaker_selection_agent)\n\u001b[0;32m    760\u001b[0m \u001b[38;5;66;03m# Run the speaker selection chat\u001b[39;00m\n\u001b[1;32m--> 761\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mchecking_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_selection_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# don't use caching for the speaker selection chat\u001b[39;49;00m\n\u001b[0;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m    766\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Limiting the chat to the number of attempts, including the initial one\u001b[39;49;00m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_speaker_auto_verbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Base silence on the verbose attribute\u001b[39;49;00m\n\u001b[0;32m    769\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_speaker_selection_result(result, last_speaker, agents)\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1492\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[0;32m   1490\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m msg2send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1491\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1492\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat(recipient, clear_history)\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1191\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m   1189\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m-> 1191\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1299\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1299\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2437\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[0;32m   2435\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   2436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[1;32m-> 2437\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[0;32m   2439\u001b[0m         log_event(\n\u001b[0;32m   2440\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2441\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2445\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[0;32m   2446\u001b[0m         )\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1817\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oai_messages[sender]\n\u001b[1;32m-> 1817\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_cache\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, extracted_response)\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1836\u001b[0m, in \u001b[0;36mConversableAgent._generate_oai_reply_from_client\u001b[1;34m(self, llm_client, messages, cache)\u001b[0m\n\u001b[0;32m   1833\u001b[0m         all_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[0;32m   1835\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m-> 1836\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1840\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1841\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1842\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mextract_text_or_completion_object(response)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\oai\\client.py:1119\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[1;34m(self, **config)\u001b[0m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1118\u001b[0m     request_ts \u001b[38;5;241m=\u001b[39m get_current_ts()\n\u001b[1;32m-> 1119\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m openai_result\u001b[38;5;241m.\u001b[39mis_successful:\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\oai\\client.py:600\u001b[0m, in \u001b[0;36mOpenAIClient.create\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_reasoning_model_params(params)\n\u001b[0;32m    599\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 600\u001b[0m response \u001b[38;5;241m=\u001b[39m create_or_parse(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;66;03m# remove the system_message from the response and add it in the prompt at the start.\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_o1:\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\autogen\\oai\\client.py:406\u001b[0m, in \u001b[0;36mOpenAIClient._handle_openai_bad_request_error.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m OpenAIClient\u001b[38;5;241m.\u001b[39m_patch_messages_for_deepseek_reasoner(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    408\u001b[0m     response_json \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mC:\\Temp\\openai\\gen-ai-sd\\crewai\\.venv\\lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Completions.create() got an unexpected keyword argument 'api_base'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example travel query\n",
    "    process_customer_query(\"I need to book a flight from New York to London next week\")\n",
    "    \n",
    "    # Example finance query\n",
    "    process_customer_query(\"What are the best mutual funds to invest in for long-term growth?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3081c0-8503-45df-b306-27c7b8de7c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
